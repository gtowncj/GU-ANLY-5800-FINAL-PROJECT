{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6tkbEhdealH"
      },
      "source": [
        "# Notebook to Demonstrate Fine Tuned Gemma Model Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyCkpOmSfEjV"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "executionInfo": {
          "elapsed": 25107,
          "status": "ok",
          "timestamp": 1765303977644,
          "user": {
            "displayName": "CJ Jones",
            "userId": "13898518827327147135"
          },
          "user_tz": 300
        },
        "id": "JNfel0XDdCGh",
        "outputId": "9bb96375-4914-42e1-8b64-7e4ec28c4b80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (3.5.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.76.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (3.10)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorboard) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (5.29.5)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (3.1.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.4.0) (1.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.3)\n",
            "Requirement already satisfied: transformers>=4.51.3 in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51.3) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51.3) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51.3) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51.3) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51.3) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51.3) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51.3) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51.3) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51.3) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51.3) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.51.3) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.51.3) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.51.3) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.51.3) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.51.3) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.51.3) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.51.3) (2025.11.12)\n",
            "Requirement already satisfied: datasets>=3.3.2 in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Collecting datasets>=3.3.2\n",
            "  Downloading datasets-4.4.1-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting accelerate==1.4.0\n",
            "  Downloading accelerate-1.4.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting evaluate==0.4.3\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting bitsandbytes==0.45.3\n",
            "  Downloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
            "Collecting trl==0.21.0\n",
            "  Downloading trl-0.21.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting peft==0.14.0\n",
            "  Downloading peft-0.14.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting protobuf==5.29.1\n",
            "  Downloading protobuf-5.29.1-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Requirement already satisfied: fsspec==2025.3.0 in /usr/local/lib/python3.12/dist-packages (2025.3.0)\n",
            "Collecting python-Levenshtein\n",
            "  Downloading python_levenshtein-0.27.3-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate==1.4.0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate==1.4.0) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate==1.4.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate==1.4.0) (6.0.3)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate==1.4.0) (2.9.0+cu126)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate==1.4.0) (0.36.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate==1.4.0) (0.7.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate==0.4.3) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate==0.4.3) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate==0.4.3) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate==0.4.3) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate==0.4.3) (3.6.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate==0.4.3) (0.70.16)\n",
            "Requirement already satisfied: transformers>=4.55.0 in /usr/local/lib/python3.12/dist-packages (from trl==0.21.0) (4.57.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=3.3.2) (3.20.0)\n",
            "Collecting pyarrow>=21.0.0 (from datasets>=3.3.2)\n",
            "  Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.3.2) (0.28.1)\n",
            "Collecting Levenshtein==0.27.3 (from python-Levenshtein)\n",
            "  Downloading levenshtein-0.27.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.7 kB)\n",
            "Collecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein==0.27.3->python-Levenshtein)\n",
            "  Downloading rapidfuzz-3.14.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate==0.4.3) (3.13.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets>=3.3.2) (4.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets>=3.3.2) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets>=3.3.2) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets>=3.3.2) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets>=3.3.2) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21.0->accelerate==1.4.0) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21.0->accelerate==1.4.0) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate==0.4.3) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate==0.4.3) (2.5.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (3.5.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.55.0->trl==0.21.0) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.55.0->trl==0.21.0) (0.22.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate==0.4.3) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate==0.4.3) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate==0.4.3) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.3) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.3) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.3) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.3) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.3) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.3) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.3) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate==0.4.3) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate==1.4.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate==1.4.0) (3.0.3)\n",
            "Downloading accelerate-1.4.0-py3-none-any.whl (342 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m342.1/342.1 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.21.0-py3-none-any.whl (511 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.9/511.9 kB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading peft-0.14.0-py3-none-any.whl (374 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.8/374.8 kB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-5.29.1-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-4.4.1-py3-none-any.whl (511 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.6/511.6 kB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_levenshtein-0.27.3-py3-none-any.whl (9.5 kB)\n",
            "Downloading levenshtein-0.27.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.3/153.3 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (47.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.14.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m99.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, pyarrow, protobuf, Levenshtein, python-Levenshtein, datasets, bitsandbytes, accelerate, trl, peft, evaluate\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 18.1.0\n",
            "    Uninstalling pyarrow-18.1.0:\n",
            "      Successfully uninstalled pyarrow-18.1.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 4.0.0\n",
            "    Uninstalling datasets-4.0.0:\n",
            "      Successfully uninstalled datasets-4.0.0\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.12.0\n",
            "    Uninstalling accelerate-1.12.0:\n",
            "      Successfully uninstalled accelerate-1.12.0\n",
            "  Attempting uninstall: peft\n",
            "    Found existing installation: peft 0.18.0\n",
            "    Uninstalling peft-0.18.0:\n",
            "      Successfully uninstalled peft-0.18.0\n",
            "Successfully installed Levenshtein-0.27.3 accelerate-1.4.0 bitsandbytes-0.45.3 datasets-4.4.1 evaluate-0.4.3 peft-0.14.0 protobuf-5.29.1 pyarrow-22.0.0 python-Levenshtein-0.27.3 rapidfuzz-3.14.3 trl-0.21.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "0133104dea424618814dd5a78a57444f",
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Install Pytorch & other libraries\n",
        "%pip install \"torch>=2.4.0\" tensorboard\n",
        "\n",
        "# Install Gemma release branch from Hugging Face\n",
        "%pip install \"transformers>=4.51.3\"\n",
        "\n",
        "# Install Hugging Face libraries\n",
        "%pip install  --upgrade \\\n",
        "  \"datasets>=3.3.2\" \\\n",
        "  \"accelerate==1.4.0\" \\\n",
        "  \"evaluate==0.4.3\" \\\n",
        "  \"bitsandbytes==0.45.3\" \\\n",
        "  \"trl==0.21.0\" \\\n",
        "  \"peft==0.14.0\" \\\n",
        "  \"protobuf==5.29.1\" \\\n",
        "  \"fsspec==2025.3.0\" \\\n",
        "  python-Levenshtein \\\n",
        "  sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 2192,
          "status": "ok",
          "timestamp": 1765303979846,
          "user": {
            "displayName": "CJ Jones",
            "userId": "13898518827327147135"
          },
          "user_tz": 300
        },
        "id": "xpLrJmYeetQd",
        "outputId": "04ad23ee-8d7e-4daf-8ce6-ef8e489b65bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "JAX backend: gpu\n",
            "JAX devices: [CudaDevice(id=0)]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ[\"HF_HUB_DISABLE_XET\"] = \"1\"\n",
        "\n",
        "import jax\n",
        "print(\"JAX backend:\", jax.default_backend())\n",
        "print(\"JAX devices:\", jax.devices())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngvU3HEeejRm"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "from google.colab import userdata\n",
        "from huggingface_hub import login\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import json\n",
        "import random\n",
        "import re\n",
        "import sqlite3\n",
        "\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "import Levenshtein\n",
        "\n",
        "from huggingface_hub import login\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    AutoModelForImageTextToText,\n",
        "    BitsAndBytesConfig,\n",
        ")\n",
        "from peft import LoraConfig, PeftModel\n",
        "from trl import SFTConfig, SFTTrainer\n",
        "\n",
        "# Login into Hugging Face Hub\n",
        "hf_token = userdata.get('HF_TOKEN') # If you are running inside a Google Colab\n",
        "login(hf_token)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ByAmTIVyAoc"
      },
      "source": [
        "### Setup Repo Structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 22581,
          "status": "ok",
          "timestamp": 1765304025068,
          "user": {
            "displayName": "CJ Jones",
            "userId": "13898518827327147135"
          },
          "user_tz": 300
        },
        "id": "q2cTDXUcyET7",
        "outputId": "09af2c8d-f093-4a2e-9271-7223487be1dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')\n",
        "\n",
        "ROOT_DRIVE_DIR = \"/content/drive/MyDrive/gemma_lora_ft\"\n",
        "\n",
        "WIKISQL_DIR = Path(\"/content/WikiSQL\")\n",
        "\n",
        "DATA_DIR = Path(\"/content/data\")\n",
        "\n",
        "TRAINED_MODEL_NAME = \"gemma_text_to_sql_run_train_rank_32_20251208_075911\"\n",
        "\n",
        "TRAINED_MODEL_DIR = f\"{ROOT_DRIVE_DIR}/{TRAINED_MODEL_NAME}\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eD-YFs_17U79"
      },
      "source": [
        "### System/User Prompt with Prompt Builder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYqjRa_77Xds"
      },
      "outputs": [],
      "source": [
        "# User prompt template (used in both training & inference)\n",
        "\n",
        "def generate_raw_prompt(question: str, schema_text: str) -> str:\n",
        "    return f\"\"\"<INSTRUCTIONS>\n",
        "You are a precise text-to-SQL generator. Using the known schema of the sql database you must output only a valid SQL query and nothing else.\n",
        "</INSTRUCTIONS>\n",
        "\n",
        "<SCHEMA>\n",
        "{schema_text}\n",
        "</SCHEMA>\n",
        "\n",
        "<QUESTION>\n",
        "{question}\n",
        "</QUESTION>\n",
        "\n",
        "<SQL_Query>\n",
        "\"\"\".strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kq0WqS0Y3cZB"
      },
      "source": [
        "# Load Test WikiSQL Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 9005,
          "status": "ok",
          "timestamp": 1765304034090,
          "user": {
            "displayName": "CJ Jones",
            "userId": "13898518827327147135"
          },
          "user_tz": 300
        },
        "id": "ArdLfPzp5pzv",
        "outputId": "8879a794-67b1-43cf-cf2d-c1b004b1c74d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'WikiSQL'...\n",
            "remote: Enumerating objects: 389, done.\u001b[K\n",
            "remote: Counting objects: 100% (195/195), done.\u001b[K\n",
            "remote: Compressing objects: 100% (41/41), done.\u001b[K\n",
            "remote: Total 389 (delta 186), reused 154 (delta 154), pack-reused 194 (from 1)\u001b[K\n",
            "Receiving objects: 100% (389/389), 50.72 MiB | 15.19 MiB/s, done.\n",
            "Resolving deltas: 100% (213/213), done.\n",
            "data/\n",
            "data/train.jsonl\n",
            "data/test.tables.jsonl\n",
            "data/test.db\n",
            "data/dev.tables.jsonl\n",
            "data/dev.db\n",
            "data/test.jsonl\n",
            "data/train.tables.jsonl\n",
            "data/train.db\n",
            "data/dev.jsonl\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(WIKISQL_DIR):\n",
        "  !git clone https://github.com/salesforce/WikiSQL\n",
        "\n",
        "if not os.path.exists(DATA_DIR):\n",
        "  !tar xvjf /content/WikiSQL/data.tar.bz2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2ch_o1N5vhg"
      },
      "source": [
        "### SQLite Setup and Table Builder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rg-hJsY5zlN"
      },
      "outputs": [],
      "source": [
        "def load_tables(split=\"dev\"):\n",
        "    tables_path = DATA_DIR / f\"{split}.tables.jsonl\"\n",
        "    tables = {}\n",
        "    with open(tables_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            obj = json.loads(line)\n",
        "            tables[obj[\"id\"]] = obj\n",
        "    return tables\n",
        "\n",
        "\n",
        "def iter_split(split=\"dev\"):\n",
        "    q_path = DATA_DIR / f\"{split}.jsonl\"\n",
        "    tables = load_tables(split)\n",
        "    with open(q_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            ex = json.loads(line)\n",
        "            table = tables[ex[\"table_id\"]]\n",
        "            yield ex, table\n",
        "\n",
        "\n",
        "def build_sqlite_from_table(table_obj):\n",
        "    df = pd.DataFrame(table_obj[\"rows\"], columns=table_obj[\"header\"])\n",
        "    conn = sqlite3.connect(\":memory:\")\n",
        "    df.to_sql(\"data\", conn, index=False, if_exists=\"replace\")\n",
        "    return conn\n",
        "\n",
        "\n",
        "AGG_OPS = [\"\", \"MAX\", \"MIN\", \"COUNT\", \"SUM\", \"AVG\"]\n",
        "COND_OPS = [\"=\", \">\", \"<\", \"OP\"]\n",
        "\n",
        "\n",
        "def escape_identifier(name: str) -> str:\n",
        "    # Escape internal quotes by doubling them\n",
        "    cleaned = name.replace('\"', '\"\"')\n",
        "    return f'\"{cleaned}\"'\n",
        "\n",
        "\n",
        "def logical_to_sql(sql_obj, table_obj, table_name=\"data\"):\n",
        "    sel_idx = sql_obj[\"sel\"]\n",
        "    agg_idx = sql_obj[\"agg\"]\n",
        "    conds = sql_obj[\"conds\"]\n",
        "\n",
        "    columns = table_obj[\"header\"]\n",
        "    sel_col = escape_identifier(columns[sel_idx])\n",
        "    agg = AGG_OPS[agg_idx]\n",
        "\n",
        "    # FIX: Proper aggregation syntax\n",
        "    if agg == \"\":\n",
        "        select_expr = sel_col\n",
        "    else:\n",
        "        select_expr = f\"{agg}({sel_col})\"\n",
        "\n",
        "    query = f\"SELECT {select_expr} FROM {table_name}\"\n",
        "\n",
        "    where_clauses = []\n",
        "    for col_idx, op_idx, val in conds:\n",
        "        col_name = escape_identifier(columns[col_idx])\n",
        "        op = COND_OPS[op_idx]\n",
        "\n",
        "        if isinstance(val, str):\n",
        "            v_str = \"'\" + val.replace(\"'\", \"''\") + \"'\"\n",
        "        else:\n",
        "            v_str = str(val)\n",
        "\n",
        "        if op == \"OP\":\n",
        "            op = \"=\"\n",
        "\n",
        "        where_clauses.append(f\"{col_name} {op} {v_str}\")\n",
        "\n",
        "    if where_clauses:\n",
        "        query += \" WHERE \" + \" AND \".join(where_clauses)\n",
        "\n",
        "    return query\n",
        "\n",
        "def execute_sql(conn, sql):\n",
        "    try:\n",
        "        cur = conn.cursor()\n",
        "        cur.execute(sql)\n",
        "        return cur.fetchall(), None\n",
        "    except Exception as e:\n",
        "        return None, str(e)\n",
        "\n",
        "\n",
        "def make_schema_text(table_obj):\n",
        "    \"\"\"\n",
        "    Convert WikiSQL table to the same schema format used for synthetic data,\n",
        "    so the model sees consistent inputs.\n",
        "    \"\"\"\n",
        "    cols = table_obj[\"header\"]\n",
        "    return \"\\n\".join(f\"- {c} (TEXT)\" for c in cols)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWrv5tLE55J1"
      },
      "source": [
        "### Test SQL Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HLvAxfI54at"
      },
      "outputs": [],
      "source": [
        "import sqlite3\n",
        "import re\n",
        "\n",
        "def is_sql_syntax_valid(sql):\n",
        "    \"\"\"\n",
        "    Checks SQL syntax by replacing table names with a dummy table\n",
        "    so that missing tables do NOT cause an error.\n",
        "    \"\"\"\n",
        "    sql_clean = sql.strip()\n",
        "\n",
        "    # Replace any token after FROM or JOIN with the dummy table name\n",
        "    sql_clean = re.sub(r\"(FROM|JOIN)\\s+[\\w\\.\\-]+\", r\"\\1 dummy\", sql_clean, flags=re.IGNORECASE)\n",
        "\n",
        "    conn = sqlite3.connect(\":memory:\")\n",
        "    conn.execute(\"CREATE TABLE dummy(x TEXT);\")\n",
        "\n",
        "    try:\n",
        "        conn.execute(sql_clean)\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        if \"no such table\" in str(e).lower():\n",
        "            return True   # table does not exist → ignore\n",
        "        return False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 24372,
          "status": "ok",
          "timestamp": 1765304058473,
          "user": {
            "displayName": "CJ Jones",
            "userId": "13898518827327147135"
          },
          "user_tz": 300
        },
        "id": "WYmK6PWb6B87",
        "outputId": "dfe1ce1c-3037-46d2-c978-d3c542d78a5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WikiSQL valid queries: 15878/15878 (100.00%)\n",
            "\n",
            "Example WikiSQL errors:\n",
            "No errors — all WikiSQL queries are valid!\n"
          ]
        }
      ],
      "source": [
        "wikisql_valid = 0\n",
        "wikisql_total = 0\n",
        "wikisql_errors = []\n",
        "\n",
        "for ex, tbl in iter_split(\"test\"):\n",
        "    wikisql_total += 1\n",
        "\n",
        "    conn = build_sqlite_from_table(tbl)\n",
        "    sql = logical_to_sql(ex[\"sql\"], tbl)\n",
        "\n",
        "    result, err = execute_sql(conn, sql)\n",
        "\n",
        "    if err is None:\n",
        "        wikisql_valid += 1\n",
        "    else:\n",
        "        wikisql_errors.append((sql, err))\n",
        "\n",
        "print(f\"WikiSQL valid queries: {wikisql_valid}/{wikisql_total} \"\n",
        "      f\"({wikisql_valid / wikisql_total:.2%})\")\n",
        "\n",
        "print(\"\\nExample WikiSQL errors:\")\n",
        "if not wikisql_errors:\n",
        "    print(\"No errors — all WikiSQL queries are valid!\")\n",
        "else:\n",
        "    for i, (sql, err) in enumerate(wikisql_errors[:5]):\n",
        "        print(\"SQL:\", sql)\n",
        "        print(\"ERROR:\", err, \"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHHmzTWH6AaE"
      },
      "source": [
        "### Final Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBMbRCsa6Hrb"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "def normalize_sql(sql: str) -> str:\n",
        "    sql = sql.strip().rstrip(\";\")\n",
        "    sql = sql.replace(\"`\", '\"')\n",
        "    return sql\n",
        "\n",
        "def build_completion(sql: str) -> str:\n",
        "    sql = normalize_sql(sql)\n",
        "    return sql.lstrip() + \"\\n</SQL_Query>\"\n",
        "\n",
        "def build_training_row_from_wikisql(ex, tbl):\n",
        "    schema = make_schema_text(tbl)\n",
        "    prompt = generate_raw_prompt(ex[\"question\"], schema)\n",
        "    gold_sql = logical_to_sql(ex[\"sql\"], tbl)\n",
        "    completion = build_completion(gold_sql)\n",
        "\n",
        "    return {\n",
        "        \"prompt\": prompt,\n",
        "        \"completion\": completion\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJKZIkDx6Ky2"
      },
      "source": [
        "### Build Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 2560,
          "status": "ok",
          "timestamp": 1765304061052,
          "user": {
            "displayName": "CJ Jones",
            "userId": "13898518827327147135"
          },
          "user_tz": 300
        },
        "id": "I5g0wFUv6MOW",
        "outputId": "f23b43aa-b435-45e6-dd45-97c086f0ff01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "    features: ['prompt', 'completion'],\n",
            "    num_rows: 56355\n",
            "})\n",
            "Dataset({\n",
            "    features: ['prompt', 'completion'],\n",
            "    num_rows: 15878\n",
            "})\n",
            "Dataset({\n",
            "    features: ['prompt', 'completion'],\n",
            "    num_rows: 8421\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "train_rows = []\n",
        "for ex, tbl in iter_split(\"train\"):\n",
        "    train_rows.append(build_training_row_from_wikisql(ex, tbl))\n",
        "\n",
        "test_rows = []\n",
        "for ex, tbl in iter_split(\"test\"):\n",
        "    test_rows.append(build_training_row_from_wikisql(ex, tbl))\n",
        "\n",
        "val_rows = []\n",
        "for ex, tbl in iter_split(\"dev\"):\n",
        "    val_rows.append(build_training_row_from_wikisql(ex, tbl))\n",
        "\n",
        "train_wikisql = Dataset.from_list(train_rows)\n",
        "test_wikisql = Dataset.from_list(test_rows)\n",
        "val_wikisql = Dataset.from_list(val_rows)\n",
        "\n",
        "print(train_wikisql)\n",
        "print(test_wikisql)\n",
        "print(val_wikisql)\n",
        "\n",
        "# print(\"\\n\")\n",
        "\n",
        "# for i in range(3):\n",
        "#     print(\"PROMPT:\\n\", train_wikisql[i][\"prompt\"])\n",
        "#     print(\"COMPLETION:\\n\", train_wikisql[i][\"completion\"])\n",
        "#     print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijwiCKXJ6WrY"
      },
      "source": [
        "# Evaluation Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMnT9CBpBYtT"
      },
      "source": [
        "### Generate Cleaned SQL Query from Gemma Model with Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6XU0u0fBhag"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def clean_sql_output(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Extract a clean SQL statement from LLM output under the new tag-based format:\n",
        "\n",
        "        <SQL_Query>\n",
        "        SELECT ...\n",
        "        </SQL_Query>\n",
        "\n",
        "    Handles:\n",
        "      - missing or extra whitespace\n",
        "      - missing closing tags\n",
        "      - trailing commentary after </SQL_Query>\n",
        "      - selects the FIRST valid SQL statement\n",
        "    \"\"\"\n",
        "\n",
        "    if not text or not isinstance(text, str):\n",
        "        return \"\"\n",
        "\n",
        "    raw = text.strip()\n",
        "\n",
        "    # -------------------------------\n",
        "    # 1. Extract content inside <SQL_Query> ... </SQL_Query>\n",
        "    # -------------------------------\n",
        "    m = re.search(\n",
        "        r\"<SQL_Query>(.*?)(</SQL_Query>|$)\",\n",
        "        raw,\n",
        "        flags=re.IGNORECASE | re.DOTALL,\n",
        "    )\n",
        "\n",
        "    if m:\n",
        "        candidate = m.group(1).strip()\n",
        "    else:\n",
        "        # fallback if tag missing\n",
        "        candidate = raw\n",
        "\n",
        "    # Remove any accidental tag echoes\n",
        "    candidate = re.sub(r\"</?SQL_Query>\", \"\", candidate, flags=re.IGNORECASE).strip()\n",
        "\n",
        "    # Strip markdown fences if any\n",
        "    candidate = re.sub(r\"```sql\", \"\", candidate, flags=re.IGNORECASE)\n",
        "    candidate = candidate.replace(\"```\", \"\").strip()\n",
        "\n",
        "    # Normalize whitespace\n",
        "    candidate = re.sub(r\"[ \\t]+\", \" \", candidate)\n",
        "\n",
        "    # -------------------------------\n",
        "    # 2. Grab the first SQL keyword (fallback)\n",
        "    # -------------------------------\n",
        "    sql_start = re.compile(\n",
        "        r\"\\b(SELECT|INSERT\\s+INTO|UPDATE|DELETE\\s+FROM|CREATE\\s+TABLE)\\b\",\n",
        "        flags=re.IGNORECASE,\n",
        "    )\n",
        "\n",
        "    match = sql_start.search(candidate)\n",
        "    if not match:\n",
        "        return candidate  # return raw candidate (probably empty)\n",
        "\n",
        "    sql = candidate[match.start():].strip()\n",
        "\n",
        "    # -------------------------------\n",
        "    # 3. Remove trailing commentary or extra content\n",
        "    # -------------------------------\n",
        "    stop_tokens = [\n",
        "        \"</SQL_Query>\",\n",
        "        \"<INSTRUCTIONS>\",\n",
        "        \"<QUESTION>\",\n",
        "        \"<SCHEMA>\",\n",
        "        \"Explanation:\",\n",
        "        \"Answer:\",\n",
        "        \"Result:\",\n",
        "        \"Note:\",\n",
        "        \"\\n#\",\n",
        "        \"```\",\n",
        "    ]\n",
        "\n",
        "    end_positions = []\n",
        "    for tok in stop_tokens:\n",
        "        pos = sql.find(tok)\n",
        "        if pos > 0:\n",
        "            end_positions.append(pos)\n",
        "\n",
        "    if end_positions:\n",
        "        sql = sql[:min(end_positions)].strip()\n",
        "\n",
        "    # Remove trailing punctuation\n",
        "    sql = sql.rstrip(\";` \")\n",
        "\n",
        "    return sql.strip()\n",
        "\n",
        "\n",
        "\n",
        "def generate_sql_from_llm(question: str, schema_text: str, model) -> str:\n",
        "    \"\"\"\n",
        "    Generate SQL from a raw text prompt using continuation-style generation.\n",
        "    \"\"\"\n",
        "    # Build the same raw prompt used during training\n",
        "    prompt = generate_raw_prompt(question, schema_text)\n",
        "\n",
        "    # print(prompt)\n",
        "\n",
        "    # Tokenize\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    print\n",
        "    # Compute input length to slice off the prompt from model output\n",
        "    input_len = inputs[\"input_ids\"].shape[-1]\n",
        "\n",
        "    # Generate continuation\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=150,\n",
        "            do_sample=False,  # deterministic for evaluation\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    # Slice off the prompt to isolate model-generated SQL\n",
        "    gen_tokens = outputs[0][input_len:]\n",
        "    decoded = tokenizer.decode(gen_tokens, skip_special_tokens=True)\n",
        "\n",
        "    return clean_sql_output(decoded)\n",
        "\n",
        "\n",
        "# SQL similarity score evaluator\n",
        "def tokenize_sql(sql: str):\n",
        "    sql = sql.lower()\n",
        "    sql = re.sub(r\"[^a-z0-9_*]\", \" \", sql)\n",
        "    tokens = sql.split()\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlAWifARBFrq"
      },
      "source": [
        "### Optional Case Insensitivity Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "508ZTWq7BJj2"
      },
      "outputs": [],
      "source": [
        "def apply_case_insensitive_matching(sql: str) -> str:\n",
        "    \"\"\"\n",
        "    Rewrites any equality of the form:\n",
        "        \"Column\" = 'Value'\n",
        "    into:\n",
        "        \"Column\" = 'Value' COLLATE NOCASE\n",
        "    Only applies to string literal comparisons.\n",
        "    \"\"\"\n",
        "\n",
        "    # pattern matches: \"Column\" = 'Value'\n",
        "    pattern = r'(\".*?\")\\s*=\\s*(\\'[^\\']*\\')'\n",
        "\n",
        "    def repl(match):\n",
        "        col, val = match.groups()\n",
        "        return f'{col} = {val} COLLATE NOCASE'\n",
        "\n",
        "    return re.sub(pattern, repl, sql)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsIk49YjGiIW"
      },
      "source": [
        "### Semantic Similarity Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TB228LK7GlIe"
      },
      "outputs": [],
      "source": [
        "def jaccard_similarity(sql1: str, sql2: str) -> float:\n",
        "    \"\"\"\n",
        "    Jaccard similarity over token sets.\n",
        "    Returns value in [0,1].\n",
        "    \"\"\"\n",
        "    t1 = set(tokenize_sql(sql1))\n",
        "    t2 = set(tokenize_sql(sql2))\n",
        "\n",
        "    if not t1 and not t2:\n",
        "        return 1.0\n",
        "    return len(t1 & t2) / len(t1 | t2)\n",
        "\n",
        "\n",
        "def levenshtein_similarity(sql1: str, sql2: str) -> float:\n",
        "    \"\"\"\n",
        "    Normalized Levenshtein similarity.\n",
        "    1.0 = identical strings.\n",
        "    \"\"\"\n",
        "    sql1 = sql1.lower().strip()\n",
        "    sql2 = sql2.lower().strip()\n",
        "\n",
        "    if not sql1 and not sql2:\n",
        "        return 1.0\n",
        "\n",
        "    dist = Levenshtein.distance(sql1, sql2)\n",
        "    max_len = max(len(sql1), len(sql2))\n",
        "\n",
        "    if max_len == 0:\n",
        "        return 1.0\n",
        "    return 1 - (dist / max_len)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AE57vYmlHSuL"
      },
      "outputs": [],
      "source": [
        "def extract_select_columns(sql: str):\n",
        "    \"\"\"\n",
        "    Extract SELECT columns robustly.\n",
        "    Handles cases like:\n",
        "       SELECT a, b FROM ...\n",
        "       SELECT COUNT(a) FROM ...\n",
        "       SELECT MAX(\"col name\") FROM ...\n",
        "    \"\"\"\n",
        "    sql = sql.lower().strip()\n",
        "    m = re.search(r\"select\\s+(.*?)\\s+from\", sql)\n",
        "    if not m:\n",
        "        return set()\n",
        "\n",
        "    cols = m.group(1)\n",
        "\n",
        "    # Remove function wrappers like count(), max(), avg()\n",
        "    cols = re.sub(r\"\\b(count|max|min|sum|avg)\\s*\\(\", \"\", cols)\n",
        "    cols = cols.replace(\")\", \"\")\n",
        "\n",
        "    # Split multiple columns\n",
        "    parts = [c.strip(' \"\\'') for c in cols.split(\",\")]\n",
        "    return set(p for p in parts if p)\n",
        "\n",
        "\n",
        "def extract_where_columns(sql: str):\n",
        "    \"\"\"\n",
        "    Extract WHERE clause column names.\n",
        "    Handles AND, multiple conditions, operators, quoted columns.\n",
        "    \"\"\"\n",
        "    sql = sql.lower().strip()\n",
        "    m = re.search(r\"where\\s+(.*)\", sql)\n",
        "    if not m:\n",
        "        return set()\n",
        "\n",
        "    conditions = m.group(1)\n",
        "\n",
        "    # Split by AND\n",
        "    conds = re.split(r\"\\band\\b\", conditions)\n",
        "\n",
        "    cols = []\n",
        "    for cond in conds:\n",
        "        parts = cond.strip().split()\n",
        "        if parts:\n",
        "            col = parts[0].strip('\"\\'')\n",
        "            cols.append(col)\n",
        "\n",
        "    return set(cols)\n",
        "\n",
        "def extract_sql_operators(sql: str):\n",
        "    \"\"\"\n",
        "    Extract operators used in SQL conditions.\n",
        "    \"\"\"\n",
        "    ops = set()\n",
        "    for op in [\"=\", \">\", \"<\", \"!=\", \"<=\", \">=\", \"like\"]:\n",
        "        if op in sql.lower():\n",
        "            ops.add(op)\n",
        "    return ops\n",
        "\n",
        "\n",
        "def structural_similarity(sql1: str, sql2: str):\n",
        "    \"\"\"\n",
        "    Returns a dict with:\n",
        "       - select_match\n",
        "       - where_match\n",
        "       - op_match\n",
        "    Each value is in [0,1].\n",
        "    \"\"\"\n",
        "\n",
        "    s1_select = extract_select_columns(sql1)\n",
        "    s2_select = extract_select_columns(sql2)\n",
        "\n",
        "    s1_where = extract_where_columns(sql1)\n",
        "    s2_where = extract_where_columns(sql2)\n",
        "\n",
        "    s1_ops = extract_sql_operators(sql1)\n",
        "    s2_ops = extract_sql_operators(sql2)\n",
        "\n",
        "    def overlap(a, b):\n",
        "        if not a and not b:\n",
        "            return 1.0\n",
        "        return len(a & b) / max(1, len(a | b))\n",
        "\n",
        "    return {\n",
        "        \"select_match\": overlap(s1_select, s2_select),\n",
        "        \"where_match\": overlap(s1_where, s2_where),\n",
        "        \"op_match\": overlap(s1_ops, s2_ops),\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUTi_apPGdP8"
      },
      "source": [
        "### Experiment Evaluation Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 6484,
          "status": "ok",
          "timestamp": 1765304067614,
          "user": {
            "displayName": "CJ Jones",
            "userId": "13898518827327147135"
          },
          "user_tz": 300
        },
        "id": "TCszoHPuDICA",
        "outputId": "61503265-a6f9-4603-c598-e49d6cd85220"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/51.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (2025.11.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (2.0.2)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (6.0.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (1.5.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (4.67.1)\n",
            "Downloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=6ca2d1ea5d1785ada07feb1b7297598bd4542c961850e856b33fe07e0b11e13e\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/9d/af/01feefbe7d55ef5468796f0c68225b6788e85d9d0a281e7a70\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: portalocker, colorama, sacrebleu, rouge_score\n",
            "Successfully installed colorama-0.4.6 portalocker-3.2.0 rouge_score-0.1.2 sacrebleu-2.5.1\n"
          ]
        }
      ],
      "source": [
        "%pip install sacrebleu rouge_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205,
          "referenced_widgets": [
            "6448d09dd1c1436c8ddd193bef3b0bf4",
            "a79d07e622334f86857e4f7a3af5245e",
            "eea554bbe2c647e1981eb746dd89c71a",
            "a6460e85c7ce4888a7eafd181b0dee04",
            "ee8346ed79af4f049f6b9e7f466dcd0b",
            "75fe2a2289c14dbfad838b7b6b56b1b0",
            "ce50f596914a48c6a95b8071747ed3a5",
            "33973ea794114c04a6eb56fe2d19e4c7",
            "41ffec25ed1c403b9d154b08c4aaf938",
            "84eb7ad5394640bd9bb202d3f8ba6739",
            "b9f0da02a3b04f1383364238b17cb820",
            "d0217b4294014af9979cddb18f6e74fa",
            "21c31f2cdebe479fb70159dfa74bad8b",
            "a9a9dbb1a5da4f1580c3d318426e4a6a",
            "e95b232d486b4ff1a4f44eb60b4068e3",
            "9c214bf0e2a8455fb7298c078984f3ef",
            "960cda9f1ae742ef9e79dcee2754dcef",
            "e3a8356bfb4b477b878dc4031ca75ca7",
            "f66d59ad52d44d44bcf4d748b9747b12",
            "fdb8230b976e41f6b9f4b41774e99496",
            "719b6882fd8a4f47be9e45130300c393",
            "112f058a9ea0455480fad88274e28fe5"
          ]
        },
        "executionInfo": {
          "elapsed": 5595,
          "status": "ok",
          "timestamp": 1765304073215,
          "user": {
            "displayName": "CJ Jones",
            "userId": "13898518827327147135"
          },
          "user_tz": 300
        },
        "id": "McyYtGFFGfen",
        "outputId": "2fb086dc-df2a-4d53-c46f-0acd2c6adeb6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6448d09dd1c1436c8ddd193bef3b0bf4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d0217b4294014af9979cddb18f6e74fa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import random\n",
        "import json\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import evaluate\n",
        "from collections import Counter\n",
        "\n",
        "# -----------------------------\n",
        "#   NEW SUPPORT FUNCTIONS\n",
        "# -----------------------------\n",
        "\n",
        "bleu_metric = evaluate.load(\"sacrebleu\")\n",
        "rouge_metric = evaluate.load(\"rouge\")\n",
        "\n",
        "\n",
        "def normalize_sql_for_em(sql: str) -> str:\n",
        "    sql = sql.strip().lower()\n",
        "    sql = sql.replace(\"`\", '\"')\n",
        "    sql = \" \".join(sql.split())   # Collapse whitespace\n",
        "    return sql\n",
        "\n",
        "\n",
        "def sql_tokenize(s: str):\n",
        "    s = s.lower()\n",
        "    s = re.sub(r'[^a-z0-9_]+', ' ', s)\n",
        "    return s.split()\n",
        "\n",
        "\n",
        "def f1_score(pred: str, gold: str):\n",
        "    pred_tokens = sql_tokenize(pred)\n",
        "    gold_tokens = sql_tokenize(gold)\n",
        "\n",
        "    common = Counter(pred_tokens) & Counter(gold_tokens)\n",
        "    num_same = sum(common.values())\n",
        "\n",
        "    if len(pred_tokens) == 0 or len(gold_tokens) == 0:\n",
        "        return int(pred_tokens == gold_tokens)\n",
        "\n",
        "    precision = num_same / len(pred_tokens)\n",
        "    recall = num_same / len(gold_tokens)\n",
        "    if precision + recall == 0:\n",
        "        return 0.0\n",
        "    return 2 * precision * recall / (precision + recall)\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "#   MAIN ENHANCED EVALUATOR\n",
        "# -----------------------------\n",
        "\n",
        "def evaluate_model(\n",
        "    model,\n",
        "    sample_fraction=0.10,\n",
        "    case_insensitive_sql=True,\n",
        "    log_path=None,\n",
        "    verbose=False,\n",
        "    seed=42\n",
        "):\n",
        "    \"\"\"\n",
        "    Full evaluation over a sample of the WikiSQL test set.\n",
        "    Includes:\n",
        "      - Execution validity & correctness\n",
        "      - Jaccard / Levenshtein / Structural similarity\n",
        "      - BLEU, ROUGE, Exact Match, Token F1\n",
        "    Saves:\n",
        "      - Row-level log (JSONL)\n",
        "      - Summary statistics (appended to same log_path if provided)\n",
        "    \"\"\"\n",
        "\n",
        "    random.seed(seed)\n",
        "\n",
        "    examples = list(iter_split(\"test\"))\n",
        "    total = len(examples)\n",
        "    sample_size = int(total * sample_fraction)\n",
        "\n",
        "    sampled = random.sample(examples, sample_size)\n",
        "\n",
        "    rows = []\n",
        "    start_time = time.time()\n",
        "\n",
        "    gold_list = []\n",
        "    pred_list = []\n",
        "\n",
        "    for idx, (ex, tbl) in enumerate(tqdm(sampled, desc=\"Evaluating\")):\n",
        "        conn = build_sqlite_from_table(tbl)\n",
        "        schema = make_schema_text(tbl)\n",
        "\n",
        "        # Gold SQL + execution\n",
        "        gold_sql = logical_to_sql(ex[\"sql\"], tbl)\n",
        "        gold_res, gold_err = execute_sql(conn, gold_sql)\n",
        "\n",
        "        # Model prediction\n",
        "        pred_sql = generate_sql_from_llm(ex[\"question\"], schema, model)\n",
        "        pred_sql_exec = apply_case_insensitive_matching(pred_sql) if case_insensitive_sql else pred_sql\n",
        "        pred_res, pred_err = execute_sql(conn, pred_sql_exec)\n",
        "\n",
        "        # Track for ROUGE/BLEU/EM/F1\n",
        "        gold_list.append(gold_sql)\n",
        "        pred_list.append(pred_sql)\n",
        "\n",
        "        # Custom similarity metrics\n",
        "        jac = jaccard_similarity(gold_sql, pred_sql)\n",
        "        lev = levenshtein_similarity(gold_sql, pred_sql)\n",
        "        struct = structural_similarity(gold_sql, pred_sql)\n",
        "\n",
        "        # Execution scoring\n",
        "        exec_valid = (pred_err is None)\n",
        "        exec_correct = (exec_valid and gold_err is None and pred_res == gold_res)\n",
        "\n",
        "        rows.append({\n",
        "            \"question\": ex[\"question\"],\n",
        "            \"schema\": schema,\n",
        "            \"gold_sql\": gold_sql,\n",
        "            \"pred_sql\": pred_sql,\n",
        "            \"pred_sql_exec\": pred_sql_exec,\n",
        "            \"gold_res\": gold_res,\n",
        "            \"pred_res\": pred_res,\n",
        "            \"gold_err\": gold_err,\n",
        "            \"pred_err\": pred_err,\n",
        "            \"exec_valid\": exec_valid,\n",
        "            \"exec_correct\": exec_correct,\n",
        "            \"jaccard\": jac,\n",
        "            \"levenshtein\": lev,\n",
        "            \"select_match\": struct[\"select_match\"],\n",
        "            \"where_match\": struct[\"where_match\"],\n",
        "            \"op_match\": struct[\"op_match\"],\n",
        "        })\n",
        "\n",
        "        if verbose and idx % 50 == 0:\n",
        "            print(f\"[{idx}/{sample_size}] exec_valid={exec_valid} exec_correct={exec_correct}\")\n",
        "\n",
        "    # Build row-level DataFrame\n",
        "    df = pd.DataFrame(rows)\n",
        "\n",
        "    # -----------------------------\n",
        "    #   GLOBAL METRIC COMPUTATION\n",
        "    # -----------------------------\n",
        "\n",
        "    # BLEU\n",
        "    bleu_score = bleu_metric.compute(\n",
        "        predictions=[p.lower() for p in pred_list],\n",
        "        references=[[g.lower()] for g in gold_list]\n",
        "    )\n",
        "\n",
        "    # ROUGE\n",
        "    rouge_scores = rouge_metric.compute(\n",
        "        predictions=[p.lower() for p in pred_list],\n",
        "        references=[g.lower() for g in gold_list]\n",
        "    )\n",
        "\n",
        "    # Exact Match\n",
        "    em_scores = [\n",
        "        normalize_sql_for_em(p) == normalize_sql_for_em(g)\n",
        "        for p, g in zip(pred_list, gold_list)\n",
        "    ]\n",
        "    em = sum(em_scores) / len(em_scores)\n",
        "\n",
        "    # Token F1\n",
        "    f1_scores = [\n",
        "        f1_score(p, g)\n",
        "        for p, g in zip(pred_list, gold_list)\n",
        "    ]\n",
        "    avg_f1 = sum(f1_scores) / len(f1_scores)\n",
        "\n",
        "    # Execution metrics\n",
        "    exec_valid_rate = df[\"exec_valid\"].mean()\n",
        "    exec_correct_rate = df[\"exec_correct\"].mean()\n",
        "\n",
        "    # -----------------------------\n",
        "    #   SUMMARY DICTIONARY\n",
        "    # -----------------------------\n",
        "    summary = {\n",
        "        \"samples_evaluated\": sample_size,\n",
        "        \"execution_valid_rate\": exec_valid_rate,\n",
        "        \"execution_correct_rate\": exec_correct_rate,\n",
        "        \"BLEU\": bleu_score,\n",
        "        \"ROUGE\": rouge_scores,\n",
        "        \"Exact_Match\": em,\n",
        "        \"Token_F1\": avg_f1,\n",
        "        \"avg_jaccard\": df[\"jaccard\"].mean(),\n",
        "        \"avg_levenshtein\": df[\"levenshtein\"].mean(),\n",
        "    }\n",
        "\n",
        "    # -----------------------------\n",
        "    #   LOG RESULTS (JSONL + summary)\n",
        "    # -----------------------------\n",
        "    if log_path:\n",
        "        # Save row-level predictions\n",
        "        df.to_json(log_path, orient=\"records\", lines=True)\n",
        "\n",
        "        # Save summary as separate JSON\n",
        "        summary_path = log_path.replace(\".jsonl\", \"_summary.json\")\n",
        "        with open(summary_path, \"w\") as f:\n",
        "            json.dump(summary, f, indent=2)\n",
        "\n",
        "        print(f\"\\nSaved detailed log to: {log_path}\")\n",
        "        print(f\"Saved summary statistics to: {summary_path}\")\n",
        "\n",
        "    elapsed = time.time() - start_time\n",
        "    print(f\"\\nEvaluation completed in {elapsed/60:.2f} minutes.\")\n",
        "    print(\"\\nSummary Metrics:\\n\", json.dumps(summary, indent=2))\n",
        "\n",
        "    return df, summary\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9KYSRo_Hsui"
      },
      "source": [
        "### Experiment Evaluation Result Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vCWnnKzeZUA"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "\n",
        "\n",
        "# =====================================================\n",
        "# 1. EXECUTION SUMMARY\n",
        "# =====================================================\n",
        "def plot_execution_summary(df, save=False, save_path=\"execution_summary.png\"):\n",
        "    summary = pd.DataFrame({\n",
        "        \"Metric\": [\"Execution Valid\", \"Execution Correct\"],\n",
        "        \"Proportion\": [\n",
        "            df[\"exec_valid\"].mean(),\n",
        "            df[\"exec_correct\"].mean()\n",
        "        ]\n",
        "    })\n",
        "\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    ax = sns.barplot(\n",
        "        data=summary,\n",
        "        x=\"Metric\",\n",
        "        y=\"Proportion\",\n",
        "        hue=\"Metric\",\n",
        "        palette=[\"#76a5ff\", \"#4c8aff\"],\n",
        "        dodge=False\n",
        "    )\n",
        "    ax.set_ylim(0, 1)\n",
        "    ax.set_title(\"SQL Execution Performance Overview (Baseline)\", fontsize=17, weight=\"bold\")\n",
        "    ax.set_ylabel(\"Proportion of Predictions\")\n",
        "\n",
        "    for container in ax.containers:\n",
        "        ax.bar_label(container, fmt=\"%.2f\", fontsize=12, label_type=\"center\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    if save:\n",
        "        plt.savefig(save_path, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# =====================================================\n",
        "# 2. SIMILARITY DISTRIBUTION HISTOGRAMS\n",
        "# =====================================================\n",
        "def plot_similarity_distributions(df, save=False, save_path=\"similarity_scores.png\"):\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "    sns.histplot(df[\"jaccard\"], kde=True, ax=axes[0], bins=25, color=\"#4a90e2\")\n",
        "    axes[0].set_title(\"Jaccard Similarity Distribution (Baseline)\", fontsize=15, weight=\"bold\")\n",
        "    axes[0].set_xlabel(\"Jaccard Score\")\n",
        "    axes[0].set_xlim(0, 1)\n",
        "\n",
        "    sns.histplot(df[\"levenshtein\"], kde=True, ax=axes[1], bins=25, color=\"#50c878\")\n",
        "    axes[1].set_title(\"Levenshtein Similarity Distribution (Baseline)\", fontsize=15, weight=\"bold\")\n",
        "    axes[1].set_xlabel(\"Normalized Levenshtein Score\")\n",
        "    axes[1].set_xlim(0, 1)\n",
        "\n",
        "    fig.suptitle(\"Semantic Similarity Between Gold & Predicted SQL\", fontsize=18, weight=\"bold\")\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save:\n",
        "        plt.savefig(save_path, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# =====================================================\n",
        "# 3. ERROR BREAKDOWN (Improved layout + centered labels)\n",
        "# =====================================================\n",
        "def plot_error_breakdown(df, save=False, save_path=\"error_breakdown.png\"):\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "    sns.countplot(\n",
        "        data=df,\n",
        "        y=\"err_type\",\n",
        "        palette=[\"#8BC6FF\", \"#FFD39B\", \"#FF9B8E\"],\n",
        "        ax=ax\n",
        "    )\n",
        "\n",
        "    ax.set_title(\"SQL Prediction Error Breakdown (Baseline)\", fontsize=18, weight=\"bold\")\n",
        "    ax.set_xlabel(\"Number of Cases\")\n",
        "    ax.set_ylabel(\"Error Category\")\n",
        "\n",
        "    # Center numeric labels inside bars\n",
        "    for container in ax.containers:\n",
        "        ax.bar_label(container, fontsize=12, label_type=\"center\")\n",
        "\n",
        "    # Move explanation to right side\n",
        "    fig.text(\n",
        "        0.72, 0.55,\n",
        "        \"Legend:\\n\"\n",
        "        \"✓ Correct — matches gold result\\n\"\n",
        "        \"⚠ Wrong Result — valid SQL, wrong output\\n\"\n",
        "        \"✗ SQL Error — syntax/execution failure\",\n",
        "        fontsize=11,\n",
        "        va=\"center\",\n",
        "        bbox=dict(facecolor=\"white\", edgecolor=\"gray\", alpha=0.8)\n",
        "    )\n",
        "\n",
        "    plt.subplots_adjust(right=0.72)\n",
        "\n",
        "    if save:\n",
        "        fig.savefig(save_path, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# =====================================================\n",
        "# 4. BLEU / ROUGE OVERVIEW CHART\n",
        "# =====================================================\n",
        "def plot_text_metrics(summary_dict, save=False, save_path=\"nlp_metrics.png\"):\n",
        "    metrics = {\n",
        "        \"BLEU\": summary_dict[\"BLEU\"][\"score\"],\n",
        "        \"ROUGE-L\": summary_dict[\"ROUGE\"][\"rougeL\"],\n",
        "        \"Exact Match\": summary_dict[\"Exact_Match\"],\n",
        "        \"Token F1\": summary_dict[\"Token_F1\"]\n",
        "    }\n",
        "\n",
        "    plt.figure(figsize=(9, 5))\n",
        "    ax = sns.barplot(\n",
        "        x=list(metrics.keys()),\n",
        "        y=list(metrics.values()),\n",
        "        palette=\"viridis\"\n",
        "    )\n",
        "\n",
        "    ax.set_ylim(0, 1)\n",
        "    ax.set_title(\"Text-Based SQL Generation Metrics (Baseline)\", fontsize=18, weight=\"bold\")\n",
        "    ax.set_ylabel(\"Score (0-1)\")\n",
        "\n",
        "    for container in ax.containers:\n",
        "        ax.bar_label(container, fmt=\"%.3f\", fontsize=12, label_type=\"center\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    if save:\n",
        "        plt.savefig(save_path, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# =====================================================\n",
        "# 5. EXACT MATCH / TOKEN F1 DISTRIBUTIONS\n",
        "# =====================================================\n",
        "def plot_em_f1_distributions(df, save=False, save_path=\"em_f1_dist.png\"):\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    metrics_df = pd.DataFrame({\n",
        "        \"Exact Match\": df[\"em\"],\n",
        "        \"Token F1\": df[\"f1\"]\n",
        "    })\n",
        "\n",
        "    sns.boxplot(data=metrics_df, palette=\"Set2\")\n",
        "\n",
        "    plt.title(\"Exact Match & Token F1 Distribution (Baseline)\", fontsize=17, weight=\"bold\")\n",
        "    plt.ylabel(\"Score\")\n",
        "\n",
        "    if save:\n",
        "        plt.savefig(save_path, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# =====================================================\n",
        "# 6. SCATTER: SIMILARITY vs EXECUTION CORRECTNESS\n",
        "# =====================================================\n",
        "def plot_similarity_vs_correctness(df, save=False, save_path=\"similarity_vs_correctness.png\"):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "\n",
        "    sns.scatterplot(\n",
        "        data=df,\n",
        "        x=\"jaccard\",\n",
        "        y=\"levenshtein\",\n",
        "        hue=\"exec_correct\",\n",
        "        palette={True: \"#1f77b4\", False: \"#ff7f0e\"},\n",
        "        alpha=0.7\n",
        "    )\n",
        "\n",
        "    plt.title(\"Similarity Scores vs SQL Execution Correctness (Baseline)\", fontsize=17, weight=\"bold\")\n",
        "    plt.xlabel(\"Jaccard\")\n",
        "    plt.ylabel(\"Levenshtein\")\n",
        "\n",
        "    if save:\n",
        "        plt.savefig(save_path, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# =====================================================\n",
        "# 7. RADAR CHART (Overall Model Quality Profile)\n",
        "# =====================================================\n",
        "def plot_radar_summary(summary_dict, save=False, save_path=\"radar_summary.png\"):\n",
        "    labels = [\"BLEU\", \"ROUGE-L\", \"Exact Match\", \"Token F1\"]\n",
        "    values = [\n",
        "        summary_dict[\"BLEU\"][\"score\"],\n",
        "        summary_dict[\"ROUGE\"][\"rougeL\"],\n",
        "        summary_dict[\"Exact_Match\"],\n",
        "        summary_dict[\"Token_F1\"]\n",
        "    ]\n",
        "\n",
        "    angles = np.linspace(0, 2 * np.pi, len(labels), endpoint=False)\n",
        "    values = np.concatenate((values, [values[0]]))\n",
        "    angles = np.concatenate((angles, [angles[0]]))\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(7, 7), subplot_kw=dict(polar=True))\n",
        "    ax.plot(angles, values, linewidth=2, linestyle='solid')\n",
        "    ax.fill(angles, values, alpha=0.25)\n",
        "\n",
        "    ax.set_thetagrids(angles[:-1] * 180/np.pi, labels)\n",
        "    ax.set_title(\"Model Quality Radar Chart (Baseline)\", fontsize=18, weight=\"bold\")\n",
        "\n",
        "    ax.set_ylim(0, 1)\n",
        "\n",
        "    if save:\n",
        "        plt.savefig(save_path, bbox_inches=\"tight\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4DhhyAb3egn"
      },
      "source": [
        "# Load Trained Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDxYwYWY5bb_"
      },
      "source": [
        "### Load Baseline Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "042c628b5b3a47d4a68835b22c5c1d0d",
            "9a5aac2fe9714a92ac0c54b7b4345492",
            "fa21d77708874ca3bedaa715bd5e54f8",
            "c5bebce1277e426880666fe4017ce09e",
            "db8fa18705b648eda2443f6065d77a8d",
            "8a2f0dc6ef5448b28f6468d9b2b8dd40",
            "74cb5e73d9754a87a4af0f61718fc00b",
            "aa6aa7d6eb71493d9bd09371c0c9eab5",
            "d379ead9e50a456eb5af1af0f5a1f1e2",
            "00959ea9838b410f9555e629f8111c89",
            "09df58804c304c1487a808f1f1a5dd54"
          ]
        },
        "executionInfo": {
          "elapsed": 13661,
          "status": "ok",
          "timestamp": 1765313006018,
          "user": {
            "displayName": "CJ Jones",
            "userId": "13898518827327147135"
          },
          "user_tz": 300
        },
        "id": "s_Q50IyVAXxG",
        "outputId": "6bd0af2c-82d2-4e42-9da4-ba31f92fd4eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔄 Loading model...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "042c628b5b3a47d4a68835b22c5c1d0d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔄 Loading tokenizer...\n"
          ]
        }
      ],
      "source": [
        "# Hugging Face model id\n",
        "model_id = \"google/gemma-3-4b-pt\"  # pre-trained (not instruction-tuned)\n",
        "# For tokenizer we use the instruction-tuned tokenizer\n",
        "tokenizer_id = \"google/gemma-3-4b-it\"\n",
        "\n",
        "# Select model class based on id\n",
        "if model_id == \"google/gemma-3-4b-pt\":\n",
        "    model_class = AutoModelForCausalLM\n",
        "else:\n",
        "    model_class = AutoModelForImageTextToText\n",
        "\n",
        "# Choose dtype based on GPU capability\n",
        "if torch.cuda.is_available() and torch.cuda.get_device_capability()[0] >= 8:\n",
        "    torch_dtype = torch.bfloat16\n",
        "else:\n",
        "    torch_dtype = torch.float16\n",
        "\n",
        "# Define model init arguments\n",
        "model_kwargs = dict(\n",
        "    attn_implementation=\"sdpa\", # Use \"flash_attention_2\" when running on Ampere or newer GPU\n",
        "    torch_dtype=torch_dtype, # What torch dtype to use, defaults to auto\n",
        "    device_map=\"auto\", # Let torch decide how to load the model\n",
        ")\n",
        "\n",
        "model_kwargs[\"quantization_config\"] = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type='nf4',\n",
        "    bnb_4bit_compute_dtype=model_kwargs['torch_dtype'],\n",
        "    bnb_4bit_quant_storage=model_kwargs['torch_dtype'],\n",
        ")\n",
        "\n",
        "\n",
        "print(\"🔄 Loading model...\")\n",
        "base_model = model_class.from_pretrained(model_id, **model_kwargs)\n",
        "\n",
        "print(\"🔄 Loading tokenizer...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(tokenizer_id)\n",
        "\n",
        "# Ensure tokenizer has EOS & PAD set correctly for generation & SFT\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"left\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxkjFGHzl6r7"
      },
      "source": [
        "### Demo Visualization Helpers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3Y8SGyAll5-"
      },
      "outputs": [],
      "source": [
        "from tabulate import tabulate\n",
        "import textwrap\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# Pretty helpers\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "def normalized_levenshtein(a: str, b: str) -> float:\n",
        "    \"\"\"Return Levenshtein *similarity* in [0, 1]. 1 = identical.\"\"\"\n",
        "    a, b = a or \"\", b or \"\"\n",
        "    if a == b:\n",
        "        return 1.0\n",
        "    if len(a) == 0 or len(b) == 0:\n",
        "        return 0.0\n",
        "\n",
        "    # standard DP Levenshtein distance\n",
        "    m, n = len(a), len(b)\n",
        "    dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
        "    for i in range(m + 1):\n",
        "        dp[i][0] = i\n",
        "    for j in range(n + 1):\n",
        "        dp[0][j] = j\n",
        "\n",
        "    for i in range(1, m + 1):\n",
        "        for j in range(1, n + 1):\n",
        "            cost = 0 if a[i - 1] == b[j - 1] else 1\n",
        "            dp[i][j] = min(\n",
        "                dp[i - 1][j] + 1,      # deletion\n",
        "                dp[i][j - 1] + 1,      # insertion\n",
        "                dp[i - 1][j - 1] + cost,  # substitution\n",
        "            )\n",
        "\n",
        "    dist = dp[m][n]\n",
        "    max_len = max(m, n)\n",
        "    return 1.0 - dist / max_len\n",
        "\n",
        "\n",
        "def token_f1_score(gold_tokens, pred_tokens) -> float:\n",
        "    \"\"\"Token-level F1 using multiset overlap between gold and predicted tokens.\"\"\"\n",
        "    gold_tokens = list(gold_tokens)\n",
        "    pred_tokens = list(pred_tokens)\n",
        "\n",
        "    if not gold_tokens and not pred_tokens:\n",
        "        return 1.0\n",
        "    if not pred_tokens:\n",
        "        return 0.0\n",
        "\n",
        "    gold_counts = Counter(gold_tokens)\n",
        "    pred_counts = Counter(pred_tokens)\n",
        "\n",
        "    overlap = sum((gold_counts & pred_counts).values())\n",
        "    precision = overlap / len(pred_tokens) if pred_tokens else 0.0\n",
        "    recall = overlap / len(gold_tokens) if gold_tokens else 0.0\n",
        "\n",
        "    if precision + recall == 0:\n",
        "        return 0.0\n",
        "    return 2 * precision * recall / (precision + recall)\n",
        "\n",
        "\n",
        "def pretty_print_header(title):\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(f\"{title}\")\n",
        "    print(\"=\" * 80 + \"\\n\")\n",
        "\n",
        "def preview_table(tbl, max_rows=5):\n",
        "    \"\"\"Return a pretty preview of the table (first few rows).\"\"\"\n",
        "    headers = tbl[\"header\"]\n",
        "    rows = tbl[\"rows\"][:max_rows]\n",
        "    return tabulate(rows, headers, tablefmt=\"grid\")\n",
        "\n",
        "def pretty_sql(sql):\n",
        "    \"\"\"Indent SQL for clean display in demos.\"\"\"\n",
        "    return textwrap.indent(sql.strip(), \"    \")\n",
        "\n",
        "def strip_collate_nocase(sql: str) -> str:\n",
        "    \"\"\"\n",
        "    Remove trailing 'COLLATE NOCASE' if present.\n",
        "    Handles variations in spacing and case.\n",
        "    \"\"\"\n",
        "    if not sql:\n",
        "        return sql\n",
        "\n",
        "    # Pattern matches: COLLATE NOCASE, with optional trailing semicolon or whitespace\n",
        "    pattern = r\"\\s+collate\\s+nocase\\s*;?\\s*$\"\n",
        "    cleaned = re.sub(pattern, \"\", sql, flags=re.IGNORECASE)\n",
        "    return cleaned.strip()\n",
        "\n",
        "def compute_similarity(gold_sql, pred_sql):\n",
        "    \"\"\"Return similarity metrics using functions defined earlier in the notebook.\"\"\"\n",
        "    gold_sql_clean = strip_collate_nocase(gold_sql)\n",
        "    pred_sql_clean = strip_collate_nocase(pred_sql)\n",
        "\n",
        "    g = gold_sql_clean.lower().split()\n",
        "    p = pred_sql_clean.lower().split()\n",
        "\n",
        "    g_set, p_set = set(g), set(p)\n",
        "\n",
        "    jaccard = len(g_set & p_set) / len(g_set | p_set) if g_set | p_set else 0\n",
        "    lev = normalized_levenshtein(gold_sql, pred_sql)\n",
        "    f1 = token_f1_score(g, p)\n",
        "\n",
        "    exact = int(gold_sql.strip().lower() == pred_sql.strip().lower())\n",
        "\n",
        "    return {\n",
        "        \"Exact Match\": exact,\n",
        "        \"Jaccard\": round(jaccard, 3),\n",
        "        \"Levenshtein\": round(lev, 3),\n",
        "        \"Token F1\": round(f1, 3),\n",
        "    }\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8GwUrDCBPON"
      },
      "source": [
        "### Test Model Output Anecdotally"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 6047,
          "status": "ok",
          "timestamp": 1765313979106,
          "user": {
            "displayName": "CJ Jones",
            "userId": "13898518827327147135"
          },
          "user_tz": 300
        },
        "id": "dmqF48RYmugM",
        "outputId": "737514cc-82bb-47e5-a400-08e07ab5f059"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "📌📌📌📌⭐ Example 1📌📌📌📌\n",
            "================================================================================\n",
            "\n",
            "**Table Preview (first rows)**\n",
            "+----------+-----------+-----------------------------+-------------------+-----------------+-----------------------------+\n",
            "|   Total# |   Series# | Title                       | Writer            | Director        | Original air date           |\n",
            "+==========+===========+=============================+===================+=================+=============================+\n",
            "|       14 |         1 | \" Sister Hood \"             | Dominic Minghella | Ciaran Donnelly | 6October2007 , 7.30–8.15pm  |\n",
            "+----------+-----------+-----------------------------+-------------------+-----------------+-----------------------------+\n",
            "|       15 |         2 | \" The Booby and the Beast \" | Simon Ashford     | Ciaran Donnelly | 13October2007 , 7.30–8.15pm |\n",
            "+----------+-----------+-----------------------------+-------------------+-----------------+-----------------------------+\n",
            "|       16 |         3 | \" Childhood \"               | Jason Sutton      | Ciaran Donnelly | 20October2007 , 7.15–8.00pm |\n",
            "+----------+-----------+-----------------------------+-------------------+-----------------+-----------------------------+\n",
            "|       17 |         4 | \" The Angel of Death \"      | Julian Unthank    | Matthew Evans   | 27October2007 , 7.15–8.00pm |\n",
            "+----------+-----------+-----------------------------+-------------------+-----------------+-----------------------------+\n",
            "|       18 |         5 | \" Ducking and Diving \"      | Debbie Oates      | Matthew Evans   | 3November2007 , 7.15–8.00pm |\n",
            "+----------+-----------+-----------------------------+-------------------+-----------------+-----------------------------+\n",
            "\n",
            "\n",
            "**Schema Used**\n",
            "    - Total# (TEXT)\n",
            "    - Series# (TEXT)\n",
            "    - Title (TEXT)\n",
            "    - Writer (TEXT)\n",
            "    - Director (TEXT)\n",
            "    - Original air date (TEXT)\n",
            "**Question**\n",
            "    Who is the director of the episode that corresponds to the total episodes number 14? \n",
            "**Gold SQL Query**\n",
            "    SELECT \"Director\" FROM data WHERE \"Total#\" = 14\n",
            "\n",
            "================================================================================\n",
            "🔵 Baseline Model Prediction\n",
            "================================================================================\n",
            "\n",
            "**Generated SQL**\n",
            "    SELECT Director FROM Series WHERE Total = 14\n",
            "**Execution Result**\n",
            "ERROR: no such table: Series\n",
            "**Similarity Metrics**\n",
            "╒═════════════╤═════════╕\n",
            "│ Metric      │   Value │\n",
            "╞═════════════╪═════════╡\n",
            "│ Exact Match │   0     │\n",
            "├─────────────┼─────────┤\n",
            "│ Jaccard     │   0.455 │\n",
            "├─────────────┼─────────┤\n",
            "│ Levenshtein │   0.766 │\n",
            "├─────────────┼─────────┤\n",
            "│ Token F1    │   0.625 │\n",
            "╘═════════════╧═════════╛\n",
            "\n",
            "================================================================================\n",
            "📊 Execution Summary\n",
            "================================================================================\n",
            "\n",
            "| Item               | Value                        |\n",
            "|--------------------|------------------------------|\n",
            "| Execution Correct? | False                        |\n",
            "| Gold Result        | [('Ciaran Donnelly',)]       |\n",
            "| Predicted Result   | ERROR: no such table: Series |\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "📌📌📌📌⭐ Example 2📌📌📌📌\n",
            "================================================================================\n",
            "\n",
            "**Table Preview (first rows)**\n",
            "+----------+-----------+-----------------------------+-------------------+-----------------+-----------------------------+\n",
            "|   Total# |   Series# | Title                       | Writer            | Director        | Original air date           |\n",
            "+==========+===========+=============================+===================+=================+=============================+\n",
            "|       14 |         1 | \" Sister Hood \"             | Dominic Minghella | Ciaran Donnelly | 6October2007 , 7.30–8.15pm  |\n",
            "+----------+-----------+-----------------------------+-------------------+-----------------+-----------------------------+\n",
            "|       15 |         2 | \" The Booby and the Beast \" | Simon Ashford     | Ciaran Donnelly | 13October2007 , 7.30–8.15pm |\n",
            "+----------+-----------+-----------------------------+-------------------+-----------------+-----------------------------+\n",
            "|       16 |         3 | \" Childhood \"               | Jason Sutton      | Ciaran Donnelly | 20October2007 , 7.15–8.00pm |\n",
            "+----------+-----------+-----------------------------+-------------------+-----------------+-----------------------------+\n",
            "|       17 |         4 | \" The Angel of Death \"      | Julian Unthank    | Matthew Evans   | 27October2007 , 7.15–8.00pm |\n",
            "+----------+-----------+-----------------------------+-------------------+-----------------+-----------------------------+\n",
            "|       18 |         5 | \" Ducking and Diving \"      | Debbie Oates      | Matthew Evans   | 3November2007 , 7.15–8.00pm |\n",
            "+----------+-----------+-----------------------------+-------------------+-----------------+-----------------------------+\n",
            "\n",
            "\n",
            "**Schema Used**\n",
            "    - Total# (TEXT)\n",
            "    - Series# (TEXT)\n",
            "    - Title (TEXT)\n",
            "    - Writer (TEXT)\n",
            "    - Director (TEXT)\n",
            "    - Original air date (TEXT)\n",
            "**Question**\n",
            "    What's the title of the episode that Rob Heyland wrote? \n",
            "**Gold SQL Query**\n",
            "    SELECT \"Title\" FROM data WHERE \"Writer\" = 'Rob Heyland'\n",
            "\n",
            "================================================================================\n",
            "🔵 Baseline Model Prediction\n",
            "================================================================================\n",
            "\n",
            "**Generated SQL**\n",
            "    SELECT Title FROM Total WHERE Writer = 'Rob Heyland'\n",
            "**Execution Result**\n",
            "ERROR: no such table: Total\n",
            "**Similarity Metrics**\n",
            "╒═════════════╤═════════╕\n",
            "│ Metric      │   Value │\n",
            "╞═════════════╪═════════╡\n",
            "│ Exact Match │   0     │\n",
            "├─────────────┼─────────┤\n",
            "│ Jaccard     │   0.5   │\n",
            "├─────────────┼─────────┤\n",
            "│ Levenshtein │   0.873 │\n",
            "├─────────────┼─────────┤\n",
            "│ Token F1    │   0.667 │\n",
            "╘═════════════╧═════════╛\n",
            "\n",
            "================================================================================\n",
            "📊 Execution Summary\n",
            "================================================================================\n",
            "\n",
            "| Item               | Value                       |\n",
            "|--------------------|-----------------------------|\n",
            "| Execution Correct? | False                       |\n",
            "| Gold Result        | [('\" For England…! \"',)]    |\n",
            "| Predicted Result   | ERROR: no such table: Total |\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "📌📌📌📌⭐ Example 3📌📌📌📌\n",
            "================================================================================\n",
            "\n",
            "**Table Preview (first rows)**\n",
            "+----------+-----------+-----------------------------+-------------------+-----------------+-----------------------------+\n",
            "|   Total# |   Series# | Title                       | Writer            | Director        | Original air date           |\n",
            "+==========+===========+=============================+===================+=================+=============================+\n",
            "|       14 |         1 | \" Sister Hood \"             | Dominic Minghella | Ciaran Donnelly | 6October2007 , 7.30–8.15pm  |\n",
            "+----------+-----------+-----------------------------+-------------------+-----------------+-----------------------------+\n",
            "|       15 |         2 | \" The Booby and the Beast \" | Simon Ashford     | Ciaran Donnelly | 13October2007 , 7.30–8.15pm |\n",
            "+----------+-----------+-----------------------------+-------------------+-----------------+-----------------------------+\n",
            "|       16 |         3 | \" Childhood \"               | Jason Sutton      | Ciaran Donnelly | 20October2007 , 7.15–8.00pm |\n",
            "+----------+-----------+-----------------------------+-------------------+-----------------+-----------------------------+\n",
            "|       17 |         4 | \" The Angel of Death \"      | Julian Unthank    | Matthew Evans   | 27October2007 , 7.15–8.00pm |\n",
            "+----------+-----------+-----------------------------+-------------------+-----------------+-----------------------------+\n",
            "|       18 |         5 | \" Ducking and Diving \"      | Debbie Oates      | Matthew Evans   | 3November2007 , 7.15–8.00pm |\n",
            "+----------+-----------+-----------------------------+-------------------+-----------------+-----------------------------+\n",
            "\n",
            "\n",
            "**Schema Used**\n",
            "    - Total# (TEXT)\n",
            "    - Series# (TEXT)\n",
            "    - Title (TEXT)\n",
            "    - Writer (TEXT)\n",
            "    - Director (TEXT)\n",
            "    - Original air date (TEXT)\n",
            "**Question**\n",
            "    What number from the total number of episodes is the episode written by Julian Unthank?\n",
            "**Gold SQL Query**\n",
            "    SELECT \"Series#\" FROM data WHERE \"Writer\" = 'Julian Unthank'\n",
            "\n",
            "================================================================================\n",
            "🔵 Baseline Model Prediction\n",
            "================================================================================\n",
            "\n",
            "**Generated SQL**\n",
            "    SELECT * FROM Total# WHERE Title = 'Julian Unthank'\n",
            "**Execution Result**\n",
            "ERROR: unrecognized token: \"#\"\n",
            "**Similarity Metrics**\n",
            "╒═════════════╤═════════╕\n",
            "│ Metric      │   Value │\n",
            "╞═════════════╪═════════╡\n",
            "│ Exact Match │   0     │\n",
            "├─────────────┼─────────┤\n",
            "│ Jaccard     │   0.5   │\n",
            "├─────────────┼─────────┤\n",
            "│ Levenshtein │   0.683 │\n",
            "├─────────────┼─────────┤\n",
            "│ Token F1    │   0.667 │\n",
            "╘═════════════╧═════════╛\n",
            "\n",
            "================================================================================\n",
            "📊 Execution Summary\n",
            "================================================================================\n",
            "\n",
            "| Item               | Value                          |\n",
            "|--------------------|--------------------------------|\n",
            "| Execution Correct? | False                          |\n",
            "| Gold Result        | [(4,)]                         |\n",
            "| Predicted Result   | ERROR: unrecognized token: \"#\" |\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ---------------------------------------------------------------------------\n",
        "#                MAIN DEMO LOOP — EXPANDED, BASELINE-ONLY VERSION\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "examples = list(iter_split(\"test\"))\n",
        "\n",
        "for i in range(3):  # Show 5 rich evaluation examples\n",
        "    ex, tbl = examples[i + 1000]\n",
        "\n",
        "    conn = build_sqlite_from_table(tbl)\n",
        "    schema = make_schema_text(tbl)\n",
        "\n",
        "    # Gold SQL from WikiSQL logical form\n",
        "    gold_sql = logical_to_sql(ex[\"sql\"], tbl)\n",
        "\n",
        "    # Baseline model SQL\n",
        "    pred_sql = generate_sql_from_llm(ex[\"question\"], schema, base_model)\n",
        "    pred_sql = apply_case_insensitive_matching(pred_sql)\n",
        "\n",
        "    # Execute queries\n",
        "    gold_res, gold_err = execute_sql(conn, gold_sql)\n",
        "    pred_res, pred_err = execute_sql(conn, pred_sql)\n",
        "\n",
        "    # -----------------------------------------------------------------------\n",
        "    # PRINT EVERYTHING IN A CLEAN, DEMO-FRIENDLY FORMAT\n",
        "    # -----------------------------------------------------------------------\n",
        "\n",
        "    pretty_print_header(f\"📌📌📌📌⭐ Example {i + 1}📌📌📌📌\")\n",
        "\n",
        "    # Table preview\n",
        "    print(\"**Table Preview (first rows)**\")\n",
        "    print(preview_table(tbl))\n",
        "    print(\"\\n\")\n",
        "\n",
        "    # Schema text\n",
        "    print(\"**Schema Used**\")\n",
        "    print(textwrap.indent(schema, \"    \"))\n",
        "    # print(\"\\n\")\n",
        "\n",
        "    # Question\n",
        "    print(\"**Question**\")\n",
        "    print(textwrap.indent(ex[\"question\"], \"    \"))\n",
        "    # print(\"\\n\")\n",
        "\n",
        "    # Gold SQL\n",
        "    print(\"**Gold SQL Query**\")\n",
        "    print(pretty_sql(gold_sql))\n",
        "    # print(\"\\n\")\n",
        "\n",
        "    # -----------------------------------------------------------------------\n",
        "    # BASELINE PREDICTION DETAILS\n",
        "    # -----------------------------------------------------------------------\n",
        "\n",
        "    pretty_print_header(\"🔵 Baseline Model Prediction\")\n",
        "\n",
        "    print(\"**Generated SQL**\")\n",
        "    print(pretty_sql(pred_sql))\n",
        "    # print(\"\\n\")\n",
        "\n",
        "    print(\"**Execution Result**\")\n",
        "    if pred_err:\n",
        "        print(f\"ERROR: {pred_err}\")\n",
        "    else:\n",
        "        print(f\"Result: {pred_res}\")\n",
        "    # print(\"\\n\")\n",
        "\n",
        "    # Similarity metrics\n",
        "    sim = compute_similarity(gold_sql, pred_sql)\n",
        "\n",
        "    print(\"**Similarity Metrics**\")\n",
        "    print(tabulate(sim.items(), headers=[\"Metric\", \"Value\"], tablefmt=\"fancy_grid\"))\n",
        "    # print(\"\\n\")\n",
        "\n",
        "    # -----------------------------------------------------------------------\n",
        "    # EXECUTION COMPARISON SUMMARY\n",
        "    # -----------------------------------------------------------------------\n",
        "\n",
        "    pretty_print_header(\"📊 Execution Summary\")\n",
        "\n",
        "    exec_correct = (gold_err is None and pred_err is None and gold_res == pred_res)\n",
        "\n",
        "    comp_table = [\n",
        "        [\"Execution Correct?\", exec_correct],\n",
        "        [\"Gold Result\", gold_res if gold_err is None else f\"ERROR: {gold_err}\"],\n",
        "        [\"Predicted Result\", pred_res if pred_err is None else f\"ERROR: {pred_err}\"],\n",
        "    ]\n",
        "\n",
        "    print(tabulate(\n",
        "        comp_table,\n",
        "        headers=[\"Item\", \"Value\"],\n",
        "        tablefmt=\"github\"\n",
        "    ))\n",
        "\n",
        "    print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoKgdELL3iM_"
      },
      "source": [
        "### Apply LoRA Adapters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 3050,
          "status": "ok",
          "timestamp": 1765314082403,
          "user": {
            "displayName": "CJ Jones",
            "userId": "13898518827327147135"
          },
          "user_tz": 300
        },
        "id": "9l3zjNYv3d_n",
        "outputId": "38c024ca-d096-4693-bedf-056fc141bb3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 1,342,504,960 || all params: 5,708,161,392 || trainable%: 23.5190\n"
          ]
        }
      ],
      "source": [
        "ft_model = PeftModel.from_pretrained(base_model, TRAINED_MODEL_DIR)\n",
        "ft_model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLKMGxwaCMuk"
      },
      "source": [
        "# Final Comparison Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 11390,
          "status": "ok",
          "timestamp": 1765314106432,
          "user": {
            "displayName": "CJ Jones",
            "userId": "13898518827327147135"
          },
          "user_tz": 300
        },
        "id": "Tio5QVt_j9Qw",
        "outputId": "f5cd899e-c538-4c22-c6ea-7fafdaf81ccb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "📌📌📌📌⭐ Example 1📌📌📌📌\n",
            "================================================================================\n",
            "\n",
            "**Table Preview (first rows)**\n",
            "+----------+-----------+-----------------------------+-------------------+-----------------+-----------------------------+\n",
            "|   Total# |   Series# | Title                       | Writer            | Director        | Original air date           |\n",
            "+==========+===========+=============================+===================+=================+=============================+\n",
            "|       14 |         1 | \" Sister Hood \"             | Dominic Minghella | Ciaran Donnelly | 6October2007 , 7.30–8.15pm  |\n",
            "+----------+-----------+-----------------------------+-------------------+-----------------+-----------------------------+\n",
            "|       15 |         2 | \" The Booby and the Beast \" | Simon Ashford     | Ciaran Donnelly | 13October2007 , 7.30–8.15pm |\n",
            "+----------+-----------+-----------------------------+-------------------+-----------------+-----------------------------+\n",
            "|       16 |         3 | \" Childhood \"               | Jason Sutton      | Ciaran Donnelly | 20October2007 , 7.15–8.00pm |\n",
            "+----------+-----------+-----------------------------+-------------------+-----------------+-----------------------------+\n",
            "|       17 |         4 | \" The Angel of Death \"      | Julian Unthank    | Matthew Evans   | 27October2007 , 7.15–8.00pm |\n",
            "+----------+-----------+-----------------------------+-------------------+-----------------+-----------------------------+\n",
            "|       18 |         5 | \" Ducking and Diving \"      | Debbie Oates      | Matthew Evans   | 3November2007 , 7.15–8.00pm |\n",
            "+----------+-----------+-----------------------------+-------------------+-----------------+-----------------------------+\n",
            "\n",
            "\n",
            "**Schema Used**\n",
            "    - Total# (TEXT)\n",
            "    - Series# (TEXT)\n",
            "    - Title (TEXT)\n",
            "    - Writer (TEXT)\n",
            "    - Director (TEXT)\n",
            "    - Original air date (TEXT)\n",
            "**Question**\n",
            "    Who is the director of the episode that corresponds to the total episodes number 14? \n",
            "**Gold SQL Query**\n",
            "    SELECT \"Director\" FROM data WHERE \"Total#\" = 14\n",
            "\n",
            "================================================================================\n",
            "🔵 Baseline Model Prediction\n",
            "================================================================================\n",
            "\n",
            "**Generated SQL**\n",
            "    SELECT \"Director\" FROM data WHERE \"Total#\" = 14\n",
            "**Execution Result**\n",
            "Result: [('Ciaran Donnelly',)]\n",
            "**Similarity Metrics**\n",
            "╒═════════════╤═════════╕\n",
            "│ Metric      │   Value │\n",
            "╞═════════════╪═════════╡\n",
            "│ Exact Match │       1 │\n",
            "├─────────────┼─────────┤\n",
            "│ Jaccard     │       1 │\n",
            "├─────────────┼─────────┤\n",
            "│ Levenshtein │       1 │\n",
            "├─────────────┼─────────┤\n",
            "│ Token F1    │       1 │\n",
            "╘═════════════╧═════════╛\n",
            "\n",
            "================================================================================\n",
            "📊 Execution Summary\n",
            "================================================================================\n",
            "\n",
            "| Item               | Value                  |\n",
            "|--------------------|------------------------|\n",
            "| Execution Correct? | True                   |\n",
            "| Gold Result        | [('Ciaran Donnelly',)] |\n",
            "| Predicted Result   | [('Ciaran Donnelly',)] |\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "📌📌📌📌⭐ Example 2📌📌📌📌\n",
            "================================================================================\n",
            "\n",
            "**Table Preview (first rows)**\n",
            "+----------+-----------+-----------------------------+-------------------+-----------------+-----------------------------+\n",
            "|   Total# |   Series# | Title                       | Writer            | Director        | Original air date           |\n",
            "+==========+===========+=============================+===================+=================+=============================+\n",
            "|       14 |         1 | \" Sister Hood \"             | Dominic Minghella | Ciaran Donnelly | 6October2007 , 7.30–8.15pm  |\n",
            "+----------+-----------+-----------------------------+-------------------+-----------------+-----------------------------+\n",
            "|       15 |         2 | \" The Booby and the Beast \" | Simon Ashford     | Ciaran Donnelly | 13October2007 , 7.30–8.15pm |\n",
            "+----------+-----------+-----------------------------+-------------------+-----------------+-----------------------------+\n",
            "|       16 |         3 | \" Childhood \"               | Jason Sutton      | Ciaran Donnelly | 20October2007 , 7.15–8.00pm |\n",
            "+----------+-----------+-----------------------------+-------------------+-----------------+-----------------------------+\n",
            "|       17 |         4 | \" The Angel of Death \"      | Julian Unthank    | Matthew Evans   | 27October2007 , 7.15–8.00pm |\n",
            "+----------+-----------+-----------------------------+-------------------+-----------------+-----------------------------+\n",
            "|       18 |         5 | \" Ducking and Diving \"      | Debbie Oates      | Matthew Evans   | 3November2007 , 7.15–8.00pm |\n",
            "+----------+-----------+-----------------------------+-------------------+-----------------+-----------------------------+\n",
            "\n",
            "\n",
            "**Schema Used**\n",
            "    - Total# (TEXT)\n",
            "    - Series# (TEXT)\n",
            "    - Title (TEXT)\n",
            "    - Writer (TEXT)\n",
            "    - Director (TEXT)\n",
            "    - Original air date (TEXT)\n",
            "**Question**\n",
            "    What's the title of the episode that Rob Heyland wrote? \n",
            "**Gold SQL Query**\n",
            "    SELECT \"Title\" FROM data WHERE \"Writer\" = 'Rob Heyland'\n",
            "\n",
            "================================================================================\n",
            "🔵 Baseline Model Prediction\n",
            "================================================================================\n",
            "\n",
            "**Generated SQL**\n",
            "    SELECT \"Title\" FROM data WHERE \"Writer\" = 'Rob Heyland' COLLATE NOCASE\n",
            "**Execution Result**\n",
            "Result: [('\" For England…! \"',)]\n",
            "**Similarity Metrics**\n",
            "╒═════════════╤═════════╕\n",
            "│ Metric      │   Value │\n",
            "╞═════════════╪═════════╡\n",
            "│ Exact Match │   0     │\n",
            "├─────────────┼─────────┤\n",
            "│ Jaccard     │   1     │\n",
            "├─────────────┼─────────┤\n",
            "│ Levenshtein │   0.786 │\n",
            "├─────────────┼─────────┤\n",
            "│ Token F1    │   1     │\n",
            "╘═════════════╧═════════╛\n",
            "\n",
            "================================================================================\n",
            "📊 Execution Summary\n",
            "================================================================================\n",
            "\n",
            "| Item               | Value                    |\n",
            "|--------------------|--------------------------|\n",
            "| Execution Correct? | True                     |\n",
            "| Gold Result        | [('\" For England…! \"',)] |\n",
            "| Predicted Result   | [('\" For England…! \"',)] |\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "📌📌📌📌⭐ Example 3📌📌📌📌\n",
            "================================================================================\n",
            "\n",
            "**Table Preview (first rows)**\n",
            "+----------+-----------+-----------------------------+-------------------+-----------------+-----------------------------+\n",
            "|   Total# |   Series# | Title                       | Writer            | Director        | Original air date           |\n",
            "+==========+===========+=============================+===================+=================+=============================+\n",
            "|       14 |         1 | \" Sister Hood \"             | Dominic Minghella | Ciaran Donnelly | 6October2007 , 7.30–8.15pm  |\n",
            "+----------+-----------+-----------------------------+-------------------+-----------------+-----------------------------+\n",
            "|       15 |         2 | \" The Booby and the Beast \" | Simon Ashford     | Ciaran Donnelly | 13October2007 , 7.30–8.15pm |\n",
            "+----------+-----------+-----------------------------+-------------------+-----------------+-----------------------------+\n",
            "|       16 |         3 | \" Childhood \"               | Jason Sutton      | Ciaran Donnelly | 20October2007 , 7.15–8.00pm |\n",
            "+----------+-----------+-----------------------------+-------------------+-----------------+-----------------------------+\n",
            "|       17 |         4 | \" The Angel of Death \"      | Julian Unthank    | Matthew Evans   | 27October2007 , 7.15–8.00pm |\n",
            "+----------+-----------+-----------------------------+-------------------+-----------------+-----------------------------+\n",
            "|       18 |         5 | \" Ducking and Diving \"      | Debbie Oates      | Matthew Evans   | 3November2007 , 7.15–8.00pm |\n",
            "+----------+-----------+-----------------------------+-------------------+-----------------+-----------------------------+\n",
            "\n",
            "\n",
            "**Schema Used**\n",
            "    - Total# (TEXT)\n",
            "    - Series# (TEXT)\n",
            "    - Title (TEXT)\n",
            "    - Writer (TEXT)\n",
            "    - Director (TEXT)\n",
            "    - Original air date (TEXT)\n",
            "**Question**\n",
            "    What number from the total number of episodes is the episode written by Julian Unthank?\n",
            "**Gold SQL Query**\n",
            "    SELECT \"Series#\" FROM data WHERE \"Writer\" = 'Julian Unthank'\n",
            "\n",
            "================================================================================\n",
            "🔵 Baseline Model Prediction\n",
            "================================================================================\n",
            "\n",
            "**Generated SQL**\n",
            "    SELECT \"Total#\" FROM data WHERE \"Writer\" = 'Julian Unthank' COLLATE NOCASE\n",
            "**Execution Result**\n",
            "Result: [(17,)]\n",
            "**Similarity Metrics**\n",
            "╒═════════════╤═════════╕\n",
            "│ Metric      │   Value │\n",
            "╞═════════════╪═════════╡\n",
            "│ Exact Match │   0     │\n",
            "├─────────────┼─────────┤\n",
            "│ Jaccard     │   0.8   │\n",
            "├─────────────┼─────────┤\n",
            "│ Levenshtein │   0.716 │\n",
            "├─────────────┼─────────┤\n",
            "│ Token F1    │   0.889 │\n",
            "╘═════════════╧═════════╛\n",
            "\n",
            "================================================================================\n",
            "📊 Execution Summary\n",
            "================================================================================\n",
            "\n",
            "| Item               | Value   |\n",
            "|--------------------|---------|\n",
            "| Execution Correct? | False   |\n",
            "| Gold Result        | [(4,)]  |\n",
            "| Predicted Result   | [(17,)] |\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ---------------------------------------------------------------------------\n",
        "#                MAIN DEMO LOOP — EXPANDED, BASELINE-ONLY VERSION\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "examples = list(iter_split(\"test\"))\n",
        "\n",
        "for i in range(3):  # Show 5 rich evaluation examples\n",
        "    ex, tbl = examples[i + 1000]\n",
        "\n",
        "    conn = build_sqlite_from_table(tbl)\n",
        "    schema = make_schema_text(tbl)\n",
        "\n",
        "    # Gold SQL from WikiSQL logical form\n",
        "    gold_sql = logical_to_sql(ex[\"sql\"], tbl)\n",
        "\n",
        "    # Baseline model SQL\n",
        "    pred_sql = generate_sql_from_llm(ex[\"question\"], schema, base_model)\n",
        "    pred_sql = apply_case_insensitive_matching(pred_sql)\n",
        "\n",
        "    # Execute queries\n",
        "    gold_res, gold_err = execute_sql(conn, gold_sql)\n",
        "    pred_res, pred_err = execute_sql(conn, pred_sql)\n",
        "\n",
        "    # -----------------------------------------------------------------------\n",
        "    # PRINT EVERYTHING IN A CLEAN, DEMO-FRIENDLY FORMAT\n",
        "    # -----------------------------------------------------------------------\n",
        "\n",
        "    pretty_print_header(f\"📌📌📌📌⭐ Example {i + 1}📌📌📌📌\")\n",
        "\n",
        "    # Table preview\n",
        "    print(\"**Table Preview (first rows)**\")\n",
        "    print(preview_table(tbl))\n",
        "    print(\"\\n\")\n",
        "\n",
        "    # Schema text\n",
        "    print(\"**Schema Used**\")\n",
        "    print(textwrap.indent(schema, \"    \"))\n",
        "    # print(\"\\n\")\n",
        "\n",
        "    # Question\n",
        "    print(\"**Question**\")\n",
        "    print(textwrap.indent(ex[\"question\"], \"    \"))\n",
        "    # print(\"\\n\")\n",
        "\n",
        "    # Gold SQL\n",
        "    print(\"**Gold SQL Query**\")\n",
        "    print(pretty_sql(gold_sql))\n",
        "    # print(\"\\n\")\n",
        "\n",
        "    # -----------------------------------------------------------------------\n",
        "    # BASELINE PREDICTION DETAILS\n",
        "    # -----------------------------------------------------------------------\n",
        "\n",
        "    pretty_print_header(\"🔵 Baseline Model Prediction\")\n",
        "\n",
        "    print(\"**Generated SQL**\")\n",
        "    print(pretty_sql(pred_sql))\n",
        "    # print(\"\\n\")\n",
        "\n",
        "    print(\"**Execution Result**\")\n",
        "    if pred_err:\n",
        "        print(f\"ERROR: {pred_err}\")\n",
        "    else:\n",
        "        print(f\"Result: {pred_res}\")\n",
        "    # print(\"\\n\")\n",
        "\n",
        "    # Similarity metrics\n",
        "    sim = compute_similarity(gold_sql, pred_sql)\n",
        "\n",
        "    print(\"**Similarity Metrics**\")\n",
        "    print(tabulate(sim.items(), headers=[\"Metric\", \"Value\"], tablefmt=\"fancy_grid\"))\n",
        "    # print(\"\\n\")\n",
        "\n",
        "    # -----------------------------------------------------------------------\n",
        "    # EXECUTION COMPARISON SUMMARY\n",
        "    # -----------------------------------------------------------------------\n",
        "\n",
        "    pretty_print_header(\"📊 Execution Summary\")\n",
        "\n",
        "    exec_correct = (gold_err is None and pred_err is None and gold_res == pred_res)\n",
        "\n",
        "    comp_table = [\n",
        "        [\"Execution Correct?\", exec_correct],\n",
        "        [\"Gold Result\", gold_res if gold_err is None else f\"ERROR: {gold_err}\"],\n",
        "        [\"Predicted Result\", pred_res if pred_err is None else f\"ERROR: {pred_err}\"],\n",
        "    ]\n",
        "\n",
        "    print(tabulate(\n",
        "        comp_table,\n",
        "        headers=[\"Item\", \"Value\"],\n",
        "        tablefmt=\"github\"\n",
        "    ))\n",
        "\n",
        "    print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upXlPw55573U"
      },
      "source": [
        "### Optional Load in Eval Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 1670,
          "status": "ok",
          "timestamp": 1765304237872,
          "user": {
            "displayName": "CJ Jones",
            "userId": "13898518827327147135"
          },
          "user_tz": 300
        },
        "id": "1fTcUrhk5_jG",
        "outputId": "b4d3498e-2e70-4a53-8325-48e9dca2501f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame loaded successfully.\n",
            "                                            question  \\\n",
            "0  Who is the Head Coach of the team whose Presid...   \n",
            "1  How many 'number of seasons in top division' w...   \n",
            "2  What height was the forward position at Crocke...   \n",
            "3  What is the score for the 2nd leg when Belasic...   \n",
            "4  Who is the winning driver of Penske Racing, an...   \n",
            "\n",
            "                                              schema  \\\n",
            "0  - Team (TEXT)\\n- Head Coach (TEXT)\\n- Presiden...   \n",
            "1  - Club (TEXT)\\n- First season in top division ...   \n",
            "2  - Name (TEXT)\\n- # (TEXT)\\n- Position (TEXT)\\n...   \n",
            "3  - Team 1 (TEXT)\\n- Agg. (TEXT)\\n- Team 2 (TEXT...   \n",
            "4  - Name (TEXT)\\n- Pole Position (TEXT)\\n- Faste...   \n",
            "\n",
            "                                            gold_sql  \\\n",
            "0  SELECT \"Head Coach\" FROM data WHERE \"President...   \n",
            "1  SELECT MAX(\"Number of seasons in top division\"...   \n",
            "2  SELECT \"Height\" FROM data WHERE \"Position\" = '...   \n",
            "3  SELECT \"2nd leg\" FROM data WHERE \"Team 2\" = 'b...   \n",
            "4  SELECT \"Winning driver\" FROM data WHERE \"Winni...   \n",
            "\n",
            "                                            pred_sql  \\\n",
            "0  SELECT Head Coach FROM Team WHERE President = ...   \n",
            "1  SELECT 'number of seasons in top division'\\nFR...   \n",
            "2  SELECT Height FROM Player WHERE Position = 'Fo...   \n",
            "3  SELECT\\n Team 2,\\n 1st leg,\\n 2nd leg\\nFROM\\n ...   \n",
            "4  SELECT Name, Pole Position, Fastest Lap, Winni...   \n",
            "\n",
            "                                       pred_sql_exec gold_res  pred_res  \\\n",
            "0  SELECT Head Coach FROM Team WHERE President = ...       []       NaN   \n",
            "1  SELECT 'number of seasons in top division'\\nFR...   [[18]]       NaN   \n",
            "2  SELECT Height FROM Player WHERE Position = 'Fo...  [[6–8]]       NaN   \n",
            "3  SELECT\\n Team 2,\\n 1st leg,\\n 2nd leg\\nFROM\\n ...       []       NaN   \n",
            "4  SELECT Name, Pole Position, Fastest Lap, Winni...       []       NaN   \n",
            "\n",
            "   gold_err                     pred_err  exec_valid  exec_correct   jaccard  \\\n",
            "0       NaN          no such table: Team       False         False  0.800000   \n",
            "1       NaN          no such table: Club       False         False  0.812500   \n",
            "2       NaN  near \"School\": syntax error       False         False  0.833333   \n",
            "3       NaN       near \"2\": syntax error       False         False  0.666667   \n",
            "4       NaN  near \"driver\": syntax error       False         False  0.666667   \n",
            "\n",
            "   levenshtein  select_match  where_match  op_match  \n",
            "0     0.880597      1.000000          1.0       1.0  \n",
            "1     0.839623      1.000000          1.0       1.0  \n",
            "2     0.752688      1.000000          1.0       1.0  \n",
            "3     0.412844      0.000000          1.0       1.0  \n",
            "4     0.446970      0.166667          0.5       1.0  \n",
            "{'samples_evaluated': 1587, 'execution_valid_rate': 0.0, 'execution_correct_rate': 0.0, 'BLEU': {'score': 12.594390342716494, 'counts': [15324, 4642, 2277, 1001], 'totals': [30769, 29182, 27595, 26008], 'precisions': [49.80337352530144, 15.907065999588788, 8.251494836021019, 3.8488157490003077], 'bp': 1.0, 'sys_len': 30769, 'ref_len': 28843}, 'ROUGE': {'rouge1': 0.7184847261105305, 'rouge2': 0.4344842006898131, 'rougeL': 0.6696477646974877, 'rougeLsum': 0.6713239061572853}, 'Exact_Match': 0.0, 'Token_F1': 0.6929059478493095, 'avg_jaccard': 0.5933727608463311, 'avg_levenshtein': 0.5695971279489761}\n"
          ]
        }
      ],
      "source": [
        "eval_df = pd.read_json(f\"{TRAINED_MODEL_DIR}/eval_results_baseline.jsonl\", lines=True)\n",
        "summary_metrics = json.load(open(f\"{TRAINED_MODEL_DIR}/eval_results_baseline_summary.json\", \"r\"))\n",
        "print(\"DataFrame loaded successfully.\")\n",
        "print(eval_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3Rtgx8ZmgrU"
      },
      "source": [
        "### OLD DEMO SETUP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "executionInfo": {
          "elapsed": 10923,
          "status": "ok",
          "timestamp": 1765304755787,
          "user": {
            "displayName": "CJ Jones",
            "userId": "13898518827327147135"
          },
          "user_tz": 300
        },
        "id": "CXUbjNQYBRI2",
        "outputId": "4fd706a5-5187-4944-f9e9-3d35303481ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "### Example 0\n",
            "Q: Who is the director of the episode that corresponds to the total episodes number 14? \n",
            "Gold: SELECT \"Director\" FROM data WHERE \"Total#\" = 14\n",
            "Pred: SELECT Director FROM Series WHERE Total = 14\n",
            "Gold result: [('Ciaran Donnelly',)]\n",
            "Pred result: ERROR: no such table: Series\n",
            "\n",
            "### Example 1\n",
            "Q: What's the title of the episode that Rob Heyland wrote? \n",
            "Gold: SELECT \"Title\" FROM data WHERE \"Writer\" = 'Rob Heyland'\n",
            "Pred: SELECT Title FROM Total WHERE Writer = 'Rob Heyland'\n",
            "Gold result: [('\" For England…! \"',)]\n",
            "Pred result: ERROR: no such table: Total\n",
            "\n",
            "### Example 2\n",
            "Q: What number from the total number of episodes is the episode written by Julian Unthank?\n",
            "Gold: SELECT \"Series#\" FROM data WHERE \"Writer\" = 'Julian Unthank'\n",
            "Pred: SELECT * FROM Total# WHERE Title = 'Julian Unthank'\n",
            "Gold result: [(4,)]\n",
            "Pred result: ERROR: unrecognized token: \"#\"\n",
            "\n",
            "### Example 3\n",
            "Q: How many touchdowns did Redden score?\n",
            "Gold: SELECT MIN(\"Touchdowns\") FROM data WHERE \"Player\" = 'Redden'\n",
            "Pred: SELECT Player, Position, Starter, Touchdowns, Extra points, Field goals, Points FROM Player\n",
            "Gold result: [(2,)]\n",
            "Pred result: ERROR: no such table: Player\n",
            "\n",
            "### Example 4\n",
            "Q: What was the most extra points?\n",
            "Gold: SELECT MAX(\"Extra points\") FROM data\n",
            "Pred: SELECT Player, Position, Starter, Touchdowns, Extra points, Field goals, Points FROM Player\n",
            "Gold result: [(4,)]\n",
            "Pred result: ERROR: no such table: Player\n"
          ]
        }
      ],
      "source": [
        "examples = list(iter_split(\"test\"))\n",
        "\n",
        "for i in range(5):                        # get 5 examples\n",
        "    ex, tbl = examples[i+1000]\n",
        "\n",
        "    conn = build_sqlite_from_table(tbl)\n",
        "    schema = make_schema_text(tbl)\n",
        "\n",
        "    gold_sql = logical_to_sql(ex[\"sql\"], tbl)\n",
        "    pred_sql = generate_sql_from_llm(ex[\"question\"], schema, base_model)\n",
        "\n",
        "    gold_res, ge = execute_sql(conn, gold_sql)\n",
        "\n",
        "    pred_sql = apply_case_insensitive_matching(pred_sql)\n",
        "    pred_res, pe = execute_sql(conn, pred_sql)\n",
        "\n",
        "    print(f\"\\n### Example {i}\")\n",
        "    print(\"Q:\", ex[\"question\"])\n",
        "    print(\"Gold:\", gold_sql)\n",
        "    print(\"Pred:\", pred_sql)\n",
        "    print(\"Gold result:\", gold_res)\n",
        "    print(\"Pred result:\", pred_res if pe is None else f\"ERROR: {pe}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyOizkgVEEg/8lTqvh3PtHr9",
      "collapsed_sections": [
        "5ByAmTIVyAoc",
        "eD-YFs_17U79",
        "Kq0WqS0Y3cZB",
        "_2ch_o1N5vhg",
        "oWrv5tLE55J1",
        "WHHmzTWH6AaE",
        "gJKZIkDx6Ky2",
        "lMnT9CBpBYtT",
        "VlAWifARBFrq",
        "RsIk49YjGiIW",
        "cUTi_apPGdP8",
        "U9KYSRo_Hsui",
        "bxkjFGHzl6r7",
        "upXlPw55573U",
        "K3Rtgx8ZmgrU"
      ],
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
