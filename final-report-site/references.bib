@article{hu2021lora,
  title        = {LoRA: Low-Rank Adaptation of Large Language Models},
  author       = {Hu, Edward and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Chen, Wei},
  journal      = {arXiv preprint arXiv:2106.09685},
  year         = {2021}
}

@article{dettmers2023qlora,
  title        = {QLoRA: Efficient Finetuning of Quantized LLMs},
  author       = {Dettmers, Tim and Pagnoni, Artidoro and Holtzman, Ari and Zettlemoyer, Luke},
  journal      = {arXiv preprint arXiv:2305.14314},
  year         = {2023}
}

@misc{larson2025lecture7,
  title        = {Lecture 7: Sequence Models and Attention Mechanisms},
  author       = {Larson, Chris},
  howpublished = {DSAN 5800: Advanced NLP, Georgetown University},
  year         = {2025},
  note         = {Fall 2025}
}

@misc{larson2025lecture8,
  title        = {Lecture 8: Transformers},
  author       = {Larson, Chris},
  howpublished = {DSAN 5800: Advanced NLP, Georgetown University},
  year         = {2025},
  note         = {Fall 2025}
}
